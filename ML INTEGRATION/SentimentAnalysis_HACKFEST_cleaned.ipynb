{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "7c578b6b870d45e3b2052b143cede452",
      "35830c4c4c54409990bd59c50d5d1d0d",
      "6bdf6d538e5f44d7b3ded2d7def9c1cd",
      "fbd8b3840d41476f80b9f9a92be64522",
      "ff7256b5b0f741199125e023f4e1a62a",
      "852539bf5e7c4933a6db2029c36bbba2",
      "ead2c3c452c141c99f4829f8e236cd0d",
      "6bfb30d2dbe8415e8e6f56ae6dc60d3d",
      "bb931f512ec24f65af4340bf79b862b1",
      "0954887259e74852acecf813f2a02744",
      "503d09b1b4024049a1f576b62b3677f4",
      "f068cb01f3044f95be7e705921ee3b33",
      "f5b8c0b939a24416a726d53f109a36c0",
      "7d1cfaab5a354106b50bfaea6ebb9843",
      "4acfe84229dc4211bf382b0194355cd0",
      "a250bdb7825a422999c66ad8cdca3df7",
      "bbd3de97616c4cda8560c43e319be163",
      "1511f41ea6824d408606c23f1150b918",
      "314ac5c7b7c14fcfbbbea25da977601a",
      "9732196be8614ae29305a903a56e5413",
      "a9cf10809ea7478381f0842fc0596449",
      "b31701d662c64c62a2bd5918ef6cead3"
     ]
    },
    "id": "7nzs5Hmw8NaP",
    "outputId": "4614bd10-7132-495a-f00c-d4643f380ed1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ†Ô∏è Preparing training data for traditional model...\n",
      "ü§ñ Training traditional TF-IDF + LR model...\n",
      "\n",
      "üìà Traditional Model Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.76      0.78      1037\n",
      "           1       0.60      0.64      0.62       970\n",
      "           2       0.75      0.74      0.75       993\n",
      "\n",
      "    accuracy                           0.72      3000\n",
      "   macro avg       0.72      0.71      0.72      3000\n",
      "weighted avg       0.72      0.72      0.72      3000\n",
      "\n",
      "üß† Fine-tuning Transformer model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c578b6b870d45e3b2052b143cede452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f068cb01f3044f95be7e705921ee3b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 04:47, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Negative</th>\n",
       "      <th>F1 Neutral</th>\n",
       "      <th>F1 Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.696700</td>\n",
       "      <td>0.642362</td>\n",
       "      <td>0.721000</td>\n",
       "      <td>0.788209</td>\n",
       "      <td>0.608558</td>\n",
       "      <td>0.754995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.579400</td>\n",
       "      <td>0.634824</td>\n",
       "      <td>0.724000</td>\n",
       "      <td>0.791978</td>\n",
       "      <td>0.613086</td>\n",
       "      <td>0.760313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.460500</td>\n",
       "      <td>0.681172</td>\n",
       "      <td>0.707667</td>\n",
       "      <td>0.768453</td>\n",
       "      <td>0.595335</td>\n",
       "      <td>0.757073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.373200</td>\n",
       "      <td>0.720636</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.605542</td>\n",
       "      <td>0.754198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Running on 15 diverse test cases:\n",
      "\n",
      "üìù The product was terrible and completely useless.\n",
      "   Traditional: NEGATIVE\n",
      "   Transformer: NEGATIVE\n",
      "   Confidence: {'negative': '0.96', 'neutral': '0.04', 'positive': '0.01'}\n",
      "\n",
      "üìù I had a bad experience with the service.\n",
      "   Traditional: NEGATIVE\n",
      "   Transformer: NEGATIVE\n",
      "   Confidence: {'negative': '0.89', 'neutral': '0.10', 'positive': '0.01'}\n",
      "\n",
      "üìù Not worth the money at all.\n",
      "   Traditional: NEGATIVE\n",
      "   Transformer: NEGATIVE\n",
      "   Confidence: {'negative': '0.95', 'neutral': '0.04', 'positive': '0.01'}\n",
      "\n",
      "üìù The item arrived broken and support was unhelpful.\n",
      "   Traditional: NEGATIVE\n",
      "   Transformer: NEGATIVE\n",
      "   Confidence: {'negative': '0.95', 'neutral': '0.04', 'positive': '0.01'}\n",
      "\n",
      "üìù Extremely disappointed by the quality.\n",
      "   Traditional: NEGATIVE\n",
      "   Transformer: NEGATIVE\n",
      "   Confidence: {'negative': '0.92', 'neutral': '0.07', 'positive': '0.01'}\n",
      "\n",
      "üìù It was okay, nothing remarkable.\n",
      "   Traditional: NEUTRAL\n",
      "   Transformer: NEUTRAL\n",
      "   Confidence: {'neutral': '0.60', 'negative': '0.37', 'positive': '0.03'}\n",
      "\n",
      "üìù The service was average, could be better.\n",
      "   Traditional: NEUTRAL\n",
      "   Transformer: NEUTRAL\n",
      "   Confidence: {'neutral': '0.67', 'negative': '0.29', 'positive': '0.04'}\n",
      "\n",
      "üìù Just fine, neither good nor bad.\n",
      "   Traditional: NEGATIVE\n",
      "   Transformer: NEGATIVE\n",
      "   Confidence: {'negative': '0.58', 'neutral': '0.40', 'positive': '0.02'}\n",
      "\n",
      "üìù I‚Äôm indifferent about the product.\n",
      "   Traditional: NEGATIVE\n",
      "   Transformer: NEGATIVE\n",
      "   Confidence: {'negative': '0.84', 'neutral': '0.14', 'positive': '0.02'}\n",
      "\n",
      "üìù Nothing to complain or praise about.\n",
      "   Traditional: NEGATIVE\n",
      "   Transformer: NEUTRAL\n",
      "   Confidence: {'neutral': '0.50', 'positive': '0.31', 'negative': '0.19'}\n",
      "\n",
      "üìù Absolutely loved it, will buy again!\n",
      "   Traditional: POSITIVE\n",
      "   Transformer: POSITIVE\n",
      "   Confidence: {'positive': '0.98', 'neutral': '0.02', 'negative': '0.01'}\n",
      "\n",
      "üìù Fantastic experience from start to end.\n",
      "   Traditional: POSITIVE\n",
      "   Transformer: POSITIVE\n",
      "   Confidence: {'positive': '0.96', 'neutral': '0.04', 'negative': '0.01'}\n",
      "\n",
      "üìù Very satisfied with the quality and service.\n",
      "   Traditional: POSITIVE\n",
      "   Transformer: POSITIVE\n",
      "   Confidence: {'positive': '0.91', 'neutral': '0.07', 'negative': '0.02'}\n",
      "\n",
      "üìù Exceeded my expectations in every way.\n",
      "   Traditional: POSITIVE\n",
      "   Transformer: POSITIVE\n",
      "   Confidence: {'positive': '0.81', 'neutral': '0.13', 'negative': '0.06'}\n",
      "\n",
      "üìù A wonderful product, highly recommended!\n",
      "   Traditional: POSITIVE\n",
      "   Transformer: POSITIVE\n",
      "   Confidence: {'positive': '0.98', 'neutral': '0.02', 'negative': '0.01'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    Trainer, TrainingArguments, pipeline\n",
    ")\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "\n",
    "class SentimentAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.device = 0 if torch.cuda.is_available() else -1\n",
    "        print(f\"Device set to use cuda:{self.device}\" if self.device == 0 else \"Using CPU.\")\n",
    "\n",
    "        self.stopwords = set(nltk.corpus.stopwords.words(\"english\")) - {'not', 'no', 'nor', 'but'}\n",
    "        self.tfidf = TfidfVectorizer(max_features=10000, ngram_range=(1, 2), stop_words=list(self.stopwords))\n",
    "        self.lr_model = LogisticRegression(max_iter=1000, solver=\"saga\", class_weight=\"balanced\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.transformer_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            \"distilbert-base-uncased\",\n",
    "            num_labels=3,\n",
    "            id2label={0: \"negative\", 1: \"neutral\", 2: \"positive\"},\n",
    "            label2id={\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "        )\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r\"http\\S+|@\\w+|[^\\w\\s]|\\d+\", \" \", text)\n",
    "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "        return \" \".join([w for w in text.split() if w not in self.stopwords])\n",
    "\n",
    "    def prepare_data(self):\n",
    "        print(\"üõ†Ô∏è Preparing training data for traditional model...\")\n",
    "        dataset = load_dataset(\"yelp_review_full\")\n",
    "        df = pd.DataFrame(dataset[\"train\"].shuffle(seed=42).select(range(30000)))\n",
    "\n",
    "        def map_labels(label):\n",
    "            if label <= 1: return 0  # negative\n",
    "            elif label == 2: return 1  # neutral\n",
    "            else: return 2  # positive\n",
    "\n",
    "        df[\"label\"] = df[\"label\"].apply(map_labels)\n",
    "\n",
    "        # Balance the dataset\n",
    "        balanced_df = pd.concat([\n",
    "            df[df[\"label\"] == 0].sample(5000),\n",
    "            df[df[\"label\"] == 1].sample(5000),\n",
    "            df[df[\"label\"] == 2].sample(5000)\n",
    "        ])\n",
    "        balanced_df[\"cleaned_text\"] = balanced_df[\"text\"].apply(self.clean_text)\n",
    "\n",
    "        train_df, test_df = train_test_split(balanced_df, test_size=0.2, random_state=42)\n",
    "        return train_df, test_df\n",
    "\n",
    "    def train_traditional_model(self, train_df, test_df):\n",
    "        print(\"ü§ñ Training traditional TF-IDF + LR model...\")\n",
    "        X_train = self.tfidf.fit_transform(train_df[\"cleaned_text\"])\n",
    "        X_test = self.tfidf.transform(test_df[\"cleaned_text\"])\n",
    "        self.lr_model.fit(X_train, train_df[\"label\"])\n",
    "        preds = self.lr_model.predict(X_test)\n",
    "        print(\"\\nüìà Traditional Model Report:\\n\", classification_report(test_df[\"label\"], preds))\n",
    "\n",
    "    def train_transformer_model(self, train_df, test_df):\n",
    "        print(\"üß† Fine-tuning Transformer model...\")\n",
    "        train_ds = Dataset.from_pandas(train_df[[\"text\", \"label\"]])\n",
    "        test_ds = Dataset.from_pandas(test_df[[\"text\", \"label\"]])\n",
    "\n",
    "        def tokenize(batch):\n",
    "            return self.tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "        train_ds = train_ds.map(tokenize, batched=True)\n",
    "        test_ds = test_ds.map(tokenize, batched=True)\n",
    "\n",
    "        train_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "        test_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "        def compute_metrics(p):\n",
    "            preds = p.predictions.argmax(-1)\n",
    "            f1s = f1_score(p.label_ids, preds, average=None)\n",
    "            return {\n",
    "                \"accuracy\": (preds == p.label_ids).mean(),\n",
    "                \"f1_negative\": f1s[0],\n",
    "                \"f1_neutral\": f1s[1],\n",
    "                \"f1_positive\": f1s[2]\n",
    "            }\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=self.transformer_model,\n",
    "            args=TrainingArguments(\n",
    "                output_dir=\"./results\",\n",
    "                evaluation_strategy=\"epoch\",\n",
    "                save_strategy=\"epoch\",\n",
    "                per_device_train_batch_size=32,\n",
    "                per_device_eval_batch_size=32,\n",
    "                num_train_epochs=4,\n",
    "                learning_rate=2e-5,\n",
    "                weight_decay=0.01,\n",
    "                logging_steps=100,\n",
    "                load_best_model_at_end=True,\n",
    "                report_to=\"none\",\n",
    "                fp16=torch.cuda.is_available()\n",
    "            ),\n",
    "            train_dataset=train_ds,\n",
    "            eval_dataset=test_ds,\n",
    "            compute_metrics=compute_metrics\n",
    "        )\n",
    "        trainer.train()\n",
    "\n",
    "        self.transformer_pipe = pipeline(\n",
    "            \"text-classification\",\n",
    "            model=self.transformer_model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            device=self.device,\n",
    "            top_k=3\n",
    "        )\n",
    "\n",
    "    def get_transformer_label(self, scores):\n",
    "        scores = {s[\"label\"].lower(): s[\"score\"] for s in scores}\n",
    "        return max(scores, key=scores.get), {k: f\"{v:.2f}\" for k, v in scores.items()}\n",
    "\n",
    "    def analyze(self, text):\n",
    "        cleaned = self.clean_text(text)\n",
    "        lr_pred = self.lr_model.predict(self.tfidf.transform([cleaned]))[0]\n",
    "        tf_scores = self.transformer_pipe(text)[0]\n",
    "        tf_label, tf_conf = self.get_transformer_label(tf_scores)\n",
    "\n",
    "        return {\n",
    "            \"text\": text,\n",
    "            \"traditional\": [\"NEGATIVE\", \"NEUTRAL\", \"POSITIVE\"][lr_pred],\n",
    "            \"transformer\": tf_label.upper(),\n",
    "            \"confidence\": tf_conf\n",
    "        }\n",
    "\n",
    "    def test_cases(self):\n",
    "        print(\"\\nüîç Running on 15 diverse test cases:\\n\")\n",
    "        examples = [\n",
    "            # NEGATIVE\n",
    "            \"The product was terrible and completely useless.\",\n",
    "            \"I had a bad experience with the service.\",\n",
    "            \"Not worth the money at all.\",\n",
    "            \"The item arrived broken and support was unhelpful.\",\n",
    "            \"Extremely disappointed by the quality.\",\n",
    "\n",
    "            # NEUTRAL\n",
    "            \"It was okay, nothing remarkable.\",\n",
    "            \"The service was average, could be better.\",\n",
    "            \"Just fine, neither good nor bad.\",\n",
    "            \"I‚Äôm indifferent about the product.\",\n",
    "            \"Nothing to complain or praise about.\",\n",
    "\n",
    "            # POSITIVE\n",
    "            \"Absolutely loved it, will buy again!\",\n",
    "            \"Fantastic experience from start to end.\",\n",
    "            \"Very satisfied with the quality and service.\",\n",
    "            \"Exceeded my expectations in every way.\",\n",
    "            \"A wonderful product, highly recommended!\"\n",
    "        ]\n",
    "        for text in examples:\n",
    "            res = self.analyze(text)\n",
    "            print(f\"üìù {res['text']}\")\n",
    "            print(f\"   Traditional: {res['traditional']}\")\n",
    "            print(f\"   Transformer: {res['transformer']}\")\n",
    "            print(f\"   Confidence: {res['confidence']}\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyzer = SentimentAnalyzer()\n",
    "    train_df, test_df = analyzer.prepare_data()\n",
    "    analyzer.train_traditional_model(train_df, test_df)\n",
    "    analyzer.train_transformer_model(train_df, test_df)\n",
    "    analyzer.test_cases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ne1gRwHD8iCB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
